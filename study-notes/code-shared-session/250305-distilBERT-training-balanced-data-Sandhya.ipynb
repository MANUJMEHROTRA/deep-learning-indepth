{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6b810a30-a6e7-4b63-93ce-ce5bb3eaa296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f078ce40-9c94-454e-9363-3e03a1def5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.2.2\n",
      "Transformers: 4.49.0\n",
      "Accelerate: 1.4.0\n",
      "Huggingface Hub: 0.29.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import accelerate\n",
    "import huggingface_hub\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Accelerate:\", accelerate.__version__)\n",
    "print(\"Huggingface Hub:\", huggingface_hub.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d2b7400-d397-4a93-961a-aee16def8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import ast\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d460b5b4-ddbd-40f4-b6ed-20f26b67545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Dataset\n",
    "# dataset = load_dataset(\"NebulaByte/E-Commerce_Customer_Support_Conversations\")\n",
    "# df = pd.DataFrame(dataset['train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9053f538-f848-4e2f-818f-b12b385d586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['issue_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4c1d0c7-b48b-4fa0-9076-70408a880abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# # Load the dataset from Hugging Face and convert to DataFrame\n",
    "# dataset = load_dataset(\"NebulaByte/E-Commerce_Customer_Support_Conversations\")\n",
    "# df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# # Check the original class distribution\n",
    "# print(\"Original distribution:\")\n",
    "# print(df['issue_area'].value_counts())\n",
    "\n",
    "# # Perform a stratified split into 512 and 488 samples\n",
    "# train_df, inference_df = train_test_split(\n",
    "#     df, \n",
    "#     test_size=488, \n",
    "#     stratify=df['issue_area'], \n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Verify the split sizes\n",
    "# print(\"\\nTraining set shape:\", train_df.shape)   # Expected ~512 rows\n",
    "# print(\"Inference set shape:\", inference_df.shape)  # Expected ~488 rows\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e17b94a-9754-4cf9-a095-25f01077039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the CSV files\n",
    "# train_df.to_csv(\"train_512.csv\", index=False)\n",
    "# inference_df.to_csv(\"inference_488.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75ddd3c0-b4df-469f-808c-5fe9f569f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(\"train_512.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da0d804d-e4d1-4e13-8c48-8da5e850e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "703a89c9-09b3-44c4-bd9d-e9dd25f7dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['issue_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a9ceafa-bcb0-4156-b788-3894f0bb3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Set the total target sample count and compute the per-class target\n",
    "# total_target = 512\n",
    "# num_classes = df['issue_area'].nunique()  # Number of unique issue areas\n",
    "# target_per_class = total_target // num_classes  # For example, if 6 classes then 512 // 6 = 85 per class\n",
    "# remainder = total_target % num_classes           # Remainder samples (e.g., 512 - 85*6 = 2)\n",
    "\n",
    "# # Create a list to hold sampled data for each class\n",
    "# balanced_samples = []\n",
    "\n",
    "# # Group the DataFrame by issue_area and sample target_per_class rows for each group\n",
    "# for issue, group in df.groupby('issue_area'):\n",
    "#     # If the group has fewer rows than target_per_class, sample with replacement (oversampling)\n",
    "#     if len(group) < target_per_class:\n",
    "#         sampled = group.sample(n=target_per_class, replace=True, random_state=42)\n",
    "#     else:\n",
    "#         sampled = group.sample(n=target_per_class, replace=False, random_state=42)\n",
    "#     balanced_samples.append(sampled)\n",
    "\n",
    "# # Concatenate all the sampled groups\n",
    "# balanced_df = pd.concat(balanced_samples).reset_index(drop=True)\n",
    "\n",
    "# # If there is a remainder, randomly sample extra rows from randomly chosen groups\n",
    "# if remainder > 0:\n",
    "#     extra_samples = []\n",
    "#     extra_classes = np.random.choice(df['issue_area'].unique(), remainder, replace=False)\n",
    "#     for cls in extra_classes:\n",
    "#         group = df[df['issue_area'] == cls]\n",
    "#         extra_sample = group.sample(n=1, replace=True, random_state=42)\n",
    "#         extra_samples.append(extra_sample)\n",
    "#     balanced_df = pd.concat([balanced_df] + extra_samples).reset_index(drop=True)\n",
    "\n",
    "# # Shuffle the final balanced DataFrame\n",
    "# balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# # Display the new balanced distribution\n",
    "# print(\"\\nBalanced distribution:\")\n",
    "# print(balanced_df['issue_area'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4dbf8b0-811d-45cc-a7f3-d13aa206a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the balanced DataFrame to a CSV file\n",
    "# balanced_df.to_csv(\"balanced_512.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66ba2e6e-3b00-46e1-b640-664e054a2bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"balanced_512.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bb49e52-67ab-424f-a962-2bc62b4bcd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issue_area\n",
       "Warranty                     86\n",
       "Shopping                     86\n",
       "Shipping                     85\n",
       "Login and Account            85\n",
       "Order                        85\n",
       "Cancellations and returns    85\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['issue_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f90d0293-c13d-490f-81bf-ba197d5aa5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_area</th>\n",
       "      <th>issue_category</th>\n",
       "      <th>issue_sub_category</th>\n",
       "      <th>issue_category_sub_category</th>\n",
       "      <th>customer_sentiment</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_sub_category</th>\n",
       "      <th>issue_complexity</th>\n",
       "      <th>agent_experience_level</th>\n",
       "      <th>agent_experience_level_desc</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shipping</td>\n",
       "      <td>Free Delivery Qualification</td>\n",
       "      <td>Reasons for an order not qualifying for free d...</td>\n",
       "      <td>Free Delivery Qualification -&gt; Reasons for an ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Men/Women/Kids</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>medium</td>\n",
       "      <td>experienced</td>\n",
       "      <td>confidently handles complex customer issues, e...</td>\n",
       "      <td>Agent: Thank you for calling BrownBox Customer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  issue_area               issue_category  \\\n",
       "0   Shipping  Free Delivery Qualification   \n",
       "\n",
       "                                  issue_sub_category  \\\n",
       "0  Reasons for an order not qualifying for free d...   \n",
       "\n",
       "                         issue_category_sub_category customer_sentiment  \\\n",
       "0  Free Delivery Qualification -> Reasons for an ...            neutral   \n",
       "\n",
       "  product_category product_sub_category issue_complexity  \\\n",
       "0   Men/Women/Kids               Diaper           medium   \n",
       "\n",
       "  agent_experience_level                        agent_experience_level_desc  \\\n",
       "0            experienced  confidently handles complex customer issues, e...   \n",
       "\n",
       "                                        conversation  \n",
       "0  Agent: Thank you for calling BrownBox Customer...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a1d8c49-d068-4dba-b154-5167f95c591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(conversation):\n",
    "    # Ensure conversation is a list\n",
    "    if isinstance(conversation, list):\n",
    "        return \" \".join([turn.get('text', '') for turn in conversation if isinstance(turn, dict)])\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8370cd50-d7cc-4110-b9bc-0bb408b00e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If conversations are stored as lists of dictionaries\n",
    "if isinstance(df['conversation'].iloc[0], list):\n",
    "    # If conversation is a list of dictionaries, preprocess it\n",
    "    df['Text'] = df['conversation'].apply(preprocess)\n",
    "else:\n",
    "    # If conversation is already plain text, just convert it to string\n",
    "    df['Text'] = df['conversation'].apply(lambda x: str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "611e95bc-6517-45f8-8101-b9ceb565ad14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Shipping', 'Warranty', 'Login and Account', 'Order', 'Shopping',\n",
       "       'Cancellations and returns'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['issue_area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d96eac17-6b30-4cf8-a9af-5b30d48effe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issue_area\n",
       "Warranty                     86\n",
       "Shopping                     86\n",
       "Shipping                     85\n",
       "Login and Account            85\n",
       "Order                        85\n",
       "Cancellations and returns    85\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['issue_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e7316fa-d307-4dfb-bc81-4ee2dc6f88d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "df['Label'] = df['issue_area'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "172d4e91-0bd3-4a5d-af85-1698643da41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 1, 2, 4, 0], dtype=int8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f47327ff-1ea7-470f-8235-9962c7b2ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, module in model.named_modules():\n",
    "#     print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a3a0afc-39af-4942-9536-050880ae14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['Text'], df['Label'], test_size=0.2, random_state=42)\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Update tokenizer max_length if needed\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=256)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=256)\n",
    "\n",
    "\n",
    "train_labels = torch.tensor(train_labels.tolist())\n",
    "test_labels = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fed0d09-7b41-436b-943d-06ef16d923cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "test_dataset = CustomDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b8e22c0-888c-4bcf-aed5-20a331346b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"  # Change model name\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(df['Label'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23512267-7f7f-4b9a-83a5-92d022a82602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights and define weighted loss (if using a custom Trainer)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(train_labels.numpy()), y=train_labels.numpy())\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "loss_function = CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f25e09c6-0316-4465-aed4-c62f7b084702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Custom Trainer that uses the weighted loss\n",
    "from transformers import Trainer\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = loss_function(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b91757f-e6bc-46f4-b0b6-1efbac80a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update LoRA config for increased capacity\n",
    "lora_config = LoraConfig(\n",
    "    r=32,                # Increased rank\n",
    "    lora_alpha=64,       # Increased scaling factor\n",
    "    lora_dropout=0.1,    # Reduced dropout\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"query\", \"value\"]  # You can experiment with adding \"key\" as well\n",
    ")\n",
    "peft_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ecb8eb2-aa8a-464e-9c83-298bd0b534a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1179648 / Total parameters: 110666502\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print trainable vs total parameters to check freezing is in effect\n",
    "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in peft_model.parameters())\n",
    "print(f\"Trainable parameters: {trainable_params} / Total parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72472cd5-1bd4-45d7-91bc-7a79cd4fed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Setup Training Arguments for CPU\n",
    "# ---------------------------\n",
    "mp.set_start_method(\"fork\", force=True)\n",
    "\n",
    "# Update training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=30,      # Increased epochs\n",
    "    learning_rate=1e-4,       # Lower learning rate\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8cfdf74-b4f6-4884-9255-917a67a7b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    labels = pred.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4910f565-4b6b-45a6-9b71-f7112797b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class WrappedPeftModel(nn.Module):\n",
    "    def __init__(self, peft_model):\n",
    "        super().__init__()\n",
    "        self.peft_model = peft_model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n",
    "        # Remove unexpected keyword arguments that the underlying model doesn't accept.\n",
    "        kwargs.pop(\"num_items_in_batch\", None)\n",
    "        return self.peft_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, **kwargs)\n",
    "\n",
    "wrapped_model = WrappedPeftModel(peft_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe69013d-826c-46e5-9348-39e377e9ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# (Optional) Subclass Trainer for Custom Loss\n",
    "# ---------------------------\n",
    "# If using a custom loss (e.g., weighted loss), you can override compute_loss.\n",
    "# For now, we assume the model's forward computes loss when labels are provided.\n",
    "# Otherwise, create a CustomTrainer that overrides compute_loss.\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Train and Evaluate\n",
    "# ---------------------------\n",
    "trainer = Trainer(\n",
    "    model=wrapped_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9df85db6-fc15-49c7-a944-88f33ffca07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='780' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [780/780 18:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.785600</td>\n",
       "      <td>1.791318</td>\n",
       "      <td>0.262136</td>\n",
       "      <td>0.147320</td>\n",
       "      <td>0.262136</td>\n",
       "      <td>0.187967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.663400</td>\n",
       "      <td>1.709562</td>\n",
       "      <td>0.320388</td>\n",
       "      <td>0.102649</td>\n",
       "      <td>0.320388</td>\n",
       "      <td>0.155483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.695500</td>\n",
       "      <td>1.670120</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.136373</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.167903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.660200</td>\n",
       "      <td>1.658329</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.206623</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.175532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.418100</td>\n",
       "      <td>1.490245</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.364771</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.358519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.392800</td>\n",
       "      <td>1.394375</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.528086</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.462914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.374800</td>\n",
       "      <td>1.333436</td>\n",
       "      <td>0.592233</td>\n",
       "      <td>0.602482</td>\n",
       "      <td>0.592233</td>\n",
       "      <td>0.541146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.302600</td>\n",
       "      <td>1.275894</td>\n",
       "      <td>0.611650</td>\n",
       "      <td>0.594333</td>\n",
       "      <td>0.611650</td>\n",
       "      <td>0.569737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.203800</td>\n",
       "      <td>1.224077</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.621939</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.600551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>1.161676</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.651872</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.634249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.044500</td>\n",
       "      <td>1.124570</td>\n",
       "      <td>0.708738</td>\n",
       "      <td>0.671090</td>\n",
       "      <td>0.708738</td>\n",
       "      <td>0.666557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.122300</td>\n",
       "      <td>1.106837</td>\n",
       "      <td>0.699029</td>\n",
       "      <td>0.664059</td>\n",
       "      <td>0.699029</td>\n",
       "      <td>0.658402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.036700</td>\n",
       "      <td>1.081697</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.783551</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.687797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.026000</td>\n",
       "      <td>1.063511</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.782186</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.703557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>1.062337</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.776531</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.696084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79        33\n",
      "           1       0.94      0.94      0.94        16\n",
      "           2       0.46      0.62      0.53        21\n",
      "           3       1.00      0.36      0.53        11\n",
      "           4       1.00      0.18      0.31        11\n",
      "           5       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.72       103\n",
      "   macro avg       0.83      0.66      0.67       103\n",
      "weighted avg       0.78      0.72      0.70       103\n",
      "\n",
      "Total Accuracy: 71.84%\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "preds_output = trainer.predict(test_dataset)\n",
    "preds = torch.argmax(torch.tensor(preds_output.predictions), dim=1)\n",
    "\n",
    "print(classification_report(test_labels, preds))\n",
    "\n",
    "\n",
    "# Print overall accuracy as a percentage\n",
    "overall_accuracy = accuracy_score(test_labels, preds)\n",
    "print(\"Total Accuracy: {:.2f}%\".format(overall_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d072529-7f83-4a78-98fd-523ad594c759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1560' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1560/1560 46:02, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.811000</td>\n",
       "      <td>1.814481</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.075795</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.095065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.765500</td>\n",
       "      <td>1.769476</td>\n",
       "      <td>0.194175</td>\n",
       "      <td>0.152029</td>\n",
       "      <td>0.194175</td>\n",
       "      <td>0.143831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.727900</td>\n",
       "      <td>1.644919</td>\n",
       "      <td>0.339806</td>\n",
       "      <td>0.266075</td>\n",
       "      <td>0.339806</td>\n",
       "      <td>0.254828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.597600</td>\n",
       "      <td>1.493049</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>0.372211</td>\n",
       "      <td>0.427184</td>\n",
       "      <td>0.363640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.331500</td>\n",
       "      <td>1.406126</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.466683</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.495554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.348900</td>\n",
       "      <td>1.349473</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.648531</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.559239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.356300</td>\n",
       "      <td>1.289282</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.689438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.311500</td>\n",
       "      <td>1.236338</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.837795</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.771695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.211300</td>\n",
       "      <td>1.201824</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.809482</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.773782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.168200</td>\n",
       "      <td>1.163892</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.810960</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.764446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.105100</td>\n",
       "      <td>1.101152</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.832226</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.805872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.061400</td>\n",
       "      <td>1.032468</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.865713</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.847291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.008000</td>\n",
       "      <td>0.987597</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.916645</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.885278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>0.922418</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.860191</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.855125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.927400</td>\n",
       "      <td>0.869894</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.881979</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.877588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.865700</td>\n",
       "      <td>0.844040</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.867685</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.852100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.809222</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.863724</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.850733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.751800</td>\n",
       "      <td>0.771086</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.872146</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.867557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.764200</td>\n",
       "      <td>0.748877</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.863003</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.851667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.769700</td>\n",
       "      <td>0.728380</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.863245</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.851986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.738700</td>\n",
       "      <td>0.703808</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.863003</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.851667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.684800</td>\n",
       "      <td>0.696968</td>\n",
       "      <td>0.844660</td>\n",
       "      <td>0.855057</td>\n",
       "      <td>0.844660</td>\n",
       "      <td>0.841860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.699900</td>\n",
       "      <td>0.680509</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.863003</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.851667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.659500</td>\n",
       "      <td>0.674436</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.882550</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.872745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>0.670585</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.863269</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.852369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.636500</td>\n",
       "      <td>0.646586</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.881236</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.877067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.599500</td>\n",
       "      <td>0.644504</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.879895</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.871615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>0.639976</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.879895</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.871615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.608700</td>\n",
       "      <td>0.631870</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.879895</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.871615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.544800</td>\n",
       "      <td>0.630957</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.879895</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.871615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.86        19\n",
      "           1       0.90      1.00      0.95        18\n",
      "           2       0.75      0.67      0.71        18\n",
      "           3       0.75      1.00      0.86        15\n",
      "           4       0.93      0.82      0.88        17\n",
      "           5       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           0.87       103\n",
      "   macro avg       0.88      0.88      0.87       103\n",
      "weighted avg       0.88      0.87      0.87       103\n",
      "\n",
      "Total Accuracy: 87.38%\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "preds_output = trainer.predict(test_dataset)\n",
    "preds = torch.argmax(torch.tensor(preds_output.predictions), dim=1)\n",
    "\n",
    "print(classification_report(test_labels, preds))\n",
    "\n",
    "\n",
    "# Print overall accuracy as a percentage\n",
    "overall_accuracy = accuracy_score(test_labels, preds)\n",
    "print(\"Total Accuracy: {:.2f}%\".format(overall_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "400e1b14-f757-47fd-a162-68d59f4fe524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the adapter weights and configuration to the specified directory.\n",
    "# peft_model.save_pretrained(\"./exp_4_87_30epc_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38b50b82-6e64-48e6-93a5-bbfadbbf5c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_area</th>\n",
       "      <th>issue_category</th>\n",
       "      <th>issue_sub_category</th>\n",
       "      <th>issue_category_sub_category</th>\n",
       "      <th>customer_sentiment</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_sub_category</th>\n",
       "      <th>issue_complexity</th>\n",
       "      <th>agent_experience_level</th>\n",
       "      <th>agent_experience_level_desc</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Login and Account</td>\n",
       "      <td>Account Reactivation and Deactivation</td>\n",
       "      <td>Reactivating an inactive account</td>\n",
       "      <td>Account Reactivation and Deactivation -&gt; React...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Microwave Oven</td>\n",
       "      <td>less</td>\n",
       "      <td>experienced</td>\n",
       "      <td>confidently handles complex customer issues, e...</td>\n",
       "      <td>Agent: Thank you for calling BrownBox customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Warranty</td>\n",
       "      <td>Product Registration and Warranty</td>\n",
       "      <td>Need to register the product with the brand fo...</td>\n",
       "      <td>Product Registration and Warranty -&gt; Need to r...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Electric Kettle</td>\n",
       "      <td>medium</td>\n",
       "      <td>junior</td>\n",
       "      <td>handles customer inquiries independently, poss...</td>\n",
       "      <td>Agent: Thank you for calling BrownBox customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Order</td>\n",
       "      <td>Order Confirmation and Status</td>\n",
       "      <td>Tracking/Shipping Updates</td>\n",
       "      <td>Order Confirmation and Status -&gt; Tracking/Ship...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>Air Cooler</td>\n",
       "      <td>less</td>\n",
       "      <td>experienced</td>\n",
       "      <td>confidently handles complex customer issues, e...</td>\n",
       "      <td>Agent: Thank you for calling BrownBox Customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Order</td>\n",
       "      <td>Order Confirmation and Status</td>\n",
       "      <td>Confirming order status</td>\n",
       "      <td>Order Confirmation and Status -&gt; Confirming or...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smart Band</td>\n",
       "      <td>less</td>\n",
       "      <td>experienced</td>\n",
       "      <td>confidently handles complex customer issues, e...</td>\n",
       "      <td>Customer: Hi, I'm calling to inquire about my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cancellations and returns</td>\n",
       "      <td>Pickup and Shipping</td>\n",
       "      <td>Pickup process</td>\n",
       "      <td>Pickup and Shipping -&gt; Pickup process</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>less</td>\n",
       "      <td>junior</td>\n",
       "      <td>handles customer inquiries independently, poss...</td>\n",
       "      <td>Customer: Hi, I would like to know about the p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  issue_area                         issue_category  \\\n",
       "0          Login and Account  Account Reactivation and Deactivation   \n",
       "1                   Warranty      Product Registration and Warranty   \n",
       "2                      Order          Order Confirmation and Status   \n",
       "3                      Order          Order Confirmation and Status   \n",
       "4  Cancellations and returns                    Pickup and Shipping   \n",
       "\n",
       "                                  issue_sub_category  \\\n",
       "0                   Reactivating an inactive account   \n",
       "1  Need to register the product with the brand fo...   \n",
       "2                          Tracking/Shipping Updates   \n",
       "3                            Confirming order status   \n",
       "4                                     Pickup process   \n",
       "\n",
       "                         issue_category_sub_category customer_sentiment  \\\n",
       "0  Account Reactivation and Deactivation -> React...           negative   \n",
       "1  Product Registration and Warranty -> Need to r...            neutral   \n",
       "2  Order Confirmation and Status -> Tracking/Ship...            neutral   \n",
       "3  Order Confirmation and Status -> Confirming or...           positive   \n",
       "4              Pickup and Shipping -> Pickup process            neutral   \n",
       "\n",
       "  product_category product_sub_category issue_complexity  \\\n",
       "0       Appliances       Microwave Oven             less   \n",
       "1       Appliances      Electric Kettle           medium   \n",
       "2       Appliances           Air Cooler             less   \n",
       "3      Electronics           Smart Band             less   \n",
       "4      Electronics               Tablet             less   \n",
       "\n",
       "  agent_experience_level                        agent_experience_level_desc  \\\n",
       "0            experienced  confidently handles complex customer issues, e...   \n",
       "1                 junior  handles customer inquiries independently, poss...   \n",
       "2            experienced  confidently handles complex customer issues, e...   \n",
       "3            experienced  confidently handles complex customer issues, e...   \n",
       "4                 junior  handles customer inquiries independently, poss...   \n",
       "\n",
       "                                        conversation  \n",
       "0  Agent: Thank you for calling BrownBox customer...  \n",
       "1  Agent: Thank you for calling BrownBox customer...  \n",
       "2  Agent: Thank you for calling BrownBox Customer...  \n",
       "3  Customer: Hi, I'm calling to inquire about my ...  \n",
       "4  Customer: Hi, I would like to know about the p...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c2bc19a8-aa88-4e12-8781-b04244dd4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the inference data from CSV\n",
    "inference_df = pd.read_csv(\"inference_488.csv\")\n",
    "\n",
    "# Assuming the conversation text is stored in a column named \"Text\"\n",
    "# (adjust the column name if necessary)\n",
    "sample_conversations = inference_df[\"conversation\"].tolist()\n",
    "\n",
    "# Create an inverted mapping: string to numeric\n",
    "inverted_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Optionally, print the first few rows to verify the data\n",
    "# print(inference_df.head())\n",
    "\n",
    "# If you have a label mapping dictionary defined (from training), e.g.:\n",
    "# label_mapping = dict(enumerate(df['issue_area'].astype('category').cat.categories))\n",
    "\n",
    "label_mapping= { \n",
    "                 0: 'Cancellations and returns',\n",
    "                 1: 'Login and Account',\n",
    "                 2: 'Order',\n",
    "                 3: 'Shipping',\n",
    "                 4: 'Shopping',\n",
    "                 5: 'Warranty'\n",
    "                }\n",
    "\n",
    "# Run inference on each sample conversation using your wrapped model\n",
    "# Note: Make sure that wrapped_model and tokenizer have been loaded (as during training)\n",
    "predictions = []\n",
    "for idx, conversation in enumerate(sample_conversations):\n",
    "    predicted_label = infer_intent(conversation, wrapped_model, tokenizer, max_length=256, device=\"cpu\")\n",
    "    predictions.append(predicted_label)\n",
    "    # print(f\"Conversation {idx+1}:\")\n",
    "    # print(conversation)\n",
    "    # print(\"Predicted Label:\", predicted_label)\n",
    "    # print(\"Predicted Intent:\", label_mapping.get(predicted_label, \"Unknown\"))\n",
    "    # print(\"-\" * 80)\n",
    "\n",
    "# Optionally, add the predictions back to the DataFrame and save to a new CSV\n",
    "inference_df[\"Predicted_Label\"] = predictions\n",
    "inference_df[\"Predicted_Intent\"] = inference_df[\"Predicted_Label\"].map(label_mapping)\n",
    "# inference_df.to_csv(\"inference_with_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "74a7fe22-c7de-4c47-9d09-062359a381e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Cancellations and returns',\n",
       " 1: 'Login and Account',\n",
       " 2: 'Order',\n",
       " 3: 'Shipping',\n",
       " 4: 'Shopping',\n",
       " 5: 'Warranty'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(enumerate(df['issue_area'].astype('category').cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bf60dad-7c45-4d16-a362-05ea00432262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 83.61%\n"
     ]
    }
   ],
   "source": [
    "# Create an inverted mapping: string to numeric\n",
    "# inverted_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "# Convert the ground truth issue areas to numeric using the inverted mapping\n",
    "ground_truth_numeric = inference_df[\"issue_area\"].map(inverted_label_mapping)\n",
    "\n",
    "# Compute overall accuracy\n",
    "acc = accuracy_score(ground_truth_numeric, predictions)\n",
    "print(\"Total Accuracy: {:.2f}%\".format(acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81ac7637-4986-475a-a033-24503e8d93a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issue_area\n",
       "Cancellations and returns    139\n",
       "Order                        132\n",
       "Login and Account             74\n",
       "Shopping                      57\n",
       "Warranty                      51\n",
       "Shipping                      35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df['issue_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45f11e-a0ba-4db2-b38d-2fd4a53728c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "21be333f-7c8d-4f99-8f48-a3e7b3dac387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation 1:\n",
      "Agent: Thank you for calling XYZ customer support. My name is Alex. How may I assist you today?\n",
      "Customer: Hi Alex, I placed an order two weeks ago and haven't received it yet. Could you check its status for me?\n",
      "Agent: Certainly. May I have your order number, please?\n",
      "Customer: Yes, it's 123456.\n",
      "Agent: Thank you. I see that there is a delay due to logistics. We are working to resolve it and will update you shortly.\n",
      "Predicted Label: 2\n",
      "Predicted Intent: Order\n",
      "--------------------------------------------------------------------------------\n",
      "Conversation 2:\n",
      "Agent: Hello, thank you for contacting our support. This is Lisa speaking. How can I help you today?\n",
      "Customer: Hi Lisa, I would like to cancel my order as I no longer need the product.\n",
      "Agent: Iâ€™m sorry to hear that. Could you please provide your order number?\n",
      "Customer: Itâ€™s 654321.\n",
      "Agent: Thank you. I have processed the cancellation and you will receive a refund within 3-5 business days.\n",
      "Predicted Label: 2\n",
      "Predicted Intent: Order\n",
      "--------------------------------------------------------------------------------\n",
      "Conversation 3:\n",
      "Agent: Good day, thank you for calling our support center. How may I assist you?\n",
      "Customer: Hello, I received an email about a shipping delay, but I havenâ€™t seen any update on my package status.\n",
      "Agent: I apologize for the inconvenience. Could you please share your tracking number?\n",
      "Customer: Sure, it's ABC123XYZ.\n",
      "Agent: Thank you. It appears that there was a delay at the distribution center. Your package should arrive soon.\n",
      "Predicted Label: 2\n",
      "Predicted Intent: Order\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "\n",
    "def infer_intent(conversation_text, model, tokenizer, max_length=256, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Performs inference on a single conversation text.\n",
    "    \n",
    "    Args:\n",
    "      conversation_text (str): The raw conversation text.\n",
    "      model: The trained LoRA-wrapped model.\n",
    "      tokenizer: The tokenizer used during training.\n",
    "      max_length (int): Maximum sequence length (must match training).\n",
    "      device (str): Device to run inference on (e.g., \"cpu\").\n",
    "      \n",
    "    Returns:\n",
    "      predicted_label (int): The predicted label index.\n",
    "    \"\"\"\n",
    "    # Ensure model is on the right device and in eval mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(\n",
    "        conversation_text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    # Move inputs to the same device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Disable gradients for inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    return predicted_label\n",
    "\n",
    "# Sample conversation data for inference\n",
    "sample_conversations = [\n",
    "\n",
    "    \"\"\"Agent: Thank you for calling XYZ customer support. My name is Alex. How may I assist you today?\n",
    "Customer: Hi Alex, I placed an order two weeks ago and haven't received it yet. Could you check its status for me?\n",
    "Agent: Certainly. May I have your order number, please?\n",
    "Customer: Yes, it's 123456.\n",
    "Agent: Thank you. I see that there is a delay due to logistics. We are working to resolve it and will update you shortly.\"\"\",\n",
    "\n",
    "\n",
    "    \"\"\"Agent: Hello, thank you for contacting our support. This is Lisa speaking. How can I help you today?\n",
    "Customer: Hi Lisa, I would like to cancel my order as I no longer need the product.\n",
    "Agent: Iâ€™m sorry to hear that. Could you please provide your order number?\n",
    "Customer: Itâ€™s 654321.\n",
    "Agent: Thank you. I have processed the cancellation and you will receive a refund within 3-5 business days.\"\"\",\n",
    "\n",
    "\n",
    "    \"\"\"Agent: Good day, thank you for calling our support center. How may I assist you?\n",
    "Customer: Hello, I received an email about a shipping delay, but I havenâ€™t seen any update on my package status.\n",
    "Agent: I apologize for the inconvenience. Could you please share your tracking number?\n",
    "Customer: Sure, it's ABC123XYZ.\n",
    "Agent: Thank you. It appears that there was a delay at the distribution center. Your package should arrive soon.\"\"\"\n",
    "]\n",
    "\n",
    "# Example: Run inference on each sample conversation\n",
    "for idx, conversation in enumerate(sample_conversations):\n",
    "    predicted_label = infer_intent(conversation, wrapped_model, tokenizer, max_length=256, device=\"cpu\")\n",
    "    \n",
    "    # If you have a mapping from label indices to intent names, you can display the intent.\n",
    "    # For example, if you computed the mapping during preprocessing:\n",
    "    label_mapping = dict(enumerate(df['issue_area'].astype('category').cat.categories))\n",
    "\n",
    "    print(f\"Conversation {idx+1}:\")\n",
    "    print(conversation)\n",
    "    print(\"Predicted Label:\", predicted_label)\n",
    "    print(\"Predicted Intent:\", label_mapping.get(predicted_label, \"Unknown\"))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c883e4c-4b00-488c-86f8-dd24aea24e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970848d-9603-4b06-bd43-97acc6154fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1733d48c-ea98-4f31-8be8-b4c9e47328d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7bd36d-7008-4270-81c4-65c9e8eb91a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
