{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peft: 0.14.0\n",
      "Torch: 2.2.2\n",
      "Transformers: 4.49.0\n",
      "Accelerate: 1.4.0\n",
      "Huggingface Hub: 0.29.1\n"
     ]
    }
   ],
   "source": [
    "# --- Common Utilities and Setup ---\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "import accelerate\n",
    "import huggingface_hub\n",
    "import peft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, accuracy_score\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, get_linear_schedule_with_warmup\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "import time\n",
    "import onnxruntime as ort\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import pickle\n",
    "\n",
    "print(\"peft:\", peft.__version__)\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Accelerate:\", accelerate.__version__)\n",
    "print(\"Huggingface Hub:\", huggingface_hub.__version__)\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Selection Function\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using Apple MPS GPU\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using NVIDIA CUDA GPU\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_dict(model_alias, MODEL_NAME):\n",
    "    if not os.path.exists('model_dict.json'):\n",
    "        model_dict = {}\n",
    "    else:\n",
    "        with open('model_dict.json', 'r') as file:\n",
    "            model_dict = json.load(file)\n",
    "\n",
    "    model_dict[model_alias] = MODEL_NAME\n",
    "\n",
    "    with open('model_dict.json', 'w') as file:\n",
    "        json.dump(model_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(filepath=\"./data/train-00000-of-00001-a5a7c6e4bb30b016.parquet\"):\n",
    "    \"\"\"Loads and preprocesses the dataset.\"\"\"\n",
    "    df = pd.read_parquet(filepath)\n",
    "    df = df[['conversation', 'issue_area']]\n",
    "    print(\"Original distribution:\\n\", df['issue_area'].value_counts())\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"labels\"] = label_encoder.fit_transform(df[\"issue_area\"])\n",
    "\n",
    "    #saving Label-encoder\n",
    "    label_encoder_path = f\"model-metric/{model_alias}/label_encoder.pkl\"\n",
    "    os.makedirs(os.path.dirname(label_encoder_path), exist_ok=True)\n",
    "    with open(label_encoder_path, \"wb\") as f:\n",
    "        pickle.dump(label_encoder, f)\n",
    "        \n",
    "    return df, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(df, max_count=100, random_state=42):\n",
    "    \"\"\"Balances the dataset using oversampling.\"\"\"\n",
    "    balanced_df = pd.DataFrame()\n",
    "    for issue in df['issue_area'].unique():\n",
    "        subset = df[df['issue_area'] == issue]\n",
    "        balanced_subset = resample(subset, replace=True, n_samples=max_count, random_state=random_state)\n",
    "        balanced_df = pd.concat([balanced_df, balanced_subset])\n",
    "    return balanced_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_conversation(conversation):\n",
    "    \"\"\"Preprocesses a conversation.\"\"\"\n",
    "    if isinstance(conversation, list):\n",
    "        return \" \".join([turn.get('text', '') for turn in conversation if isinstance(turn, dict)])\n",
    "    return str(conversation) #.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomT5Dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_source_length=512, max_target_length=15):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_source_length = max_source_length\n",
    "        self.max_target_length = max_target_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        conversation = row[\"conversation\"]\n",
    "        label = row[\"labels\"]\n",
    "        \n",
    "        # Convert label to text representation\n",
    "        label_text = label_encoder.inverse_transform([label])[0]\n",
    "        \n",
    "        # Prepare source (conversation) and target (intent) encodings\n",
    "        source_encoding = self.tokenizer(\n",
    "            conversation, \n",
    "            max_length=self.max_source_length, \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokenizer(\n",
    "            label_text, \n",
    "            max_length=self.max_target_length, \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": source_encoding[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": source_encoding[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": target_encoding[\"input_ids\"].squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(df, tokenizer, batch_size=8, train_ratio=0.75):\n",
    "    \"\"\"Creates train and test DataLoaders.\"\"\"\n",
    "    train_size = int(train_ratio * len(df))\n",
    "    train_df, test_df = df[:train_size], df[train_size:]\n",
    "    train_dataset = CustomT5Dataset(train_df, tokenizer)\n",
    "    test_dataset = CustomT5Dataset(test_df, tokenizer)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T5ForConditionalGeneration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt5 \u001b[38;5;241m=\u001b[39m \u001b[43mT5ForConditionalGeneration\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/flan-t5-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'T5ForConditionalGeneration' is not defined"
     ]
    }
   ],
   "source": [
    "self.t5 = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlanT5WithLoRA(nn.Module):\n",
    "    def __init__(self, num_labels, lora_r=8, lora_alpha=16, lora_dropout=0.1):\n",
    "        super(FlanT5WithLoRA, self).__init__()\n",
    "        # Load the base T5 model\n",
    "        self.t5 = T5ForConditionalGeneration.from_pretrained(\n",
    "            \"google/flan-t5-base\"\n",
    "        )\n",
    "        \n",
    "        # LoRA Configuration\n",
    "        lora_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "            r=lora_r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            lora_dropout=lora_dropout,\n",
    "            target_modules=[\"q\", \"k\", \"v\", \"o\"]\n",
    "        )\n",
    "        self.t5 = get_peft_model(self.t5, lora_config)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.t5(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            labels=labels\n",
    "        )\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute class weights\n",
    "def compute_class_weights(labels, num_classes):\n",
    "    counter = Counter(labels)\n",
    "    total_samples = len(labels)\n",
    "    weights = [total_samples / (num_classes * counter[i]) for i in range(num_classes)]\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, tokenizer, model_alias, epochs=3, learning_rate=5e-5):\n",
    "    \"\"\"Trains the T5 model and saves logs, metrics, and model weights.\"\"\"\n",
    "    \n",
    "    device = get_device()\n",
    "\n",
    "        # Additional MPS-specific configurations\n",
    "    if device.type == 'mps':\n",
    "        # Ensure float32 dtype for MPS compatibility\n",
    "        model = model.to(device, dtype=torch.float32)\n",
    "        \n",
    "        # Some tensor operations may need explicit conversion\n",
    "        torch.set_default_dtype(torch.float32)\n",
    "    else:\n",
    "        model = model.to(device)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Create directory for storing model metrics\n",
    "    model_dir = f\"model-metric/{model_alias}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # TensorBoard writer in the model directory\n",
    "    writer = SummaryWriter(log_dir=model_dir)\n",
    "\n",
    "    # Set up optimizer and learning rate scheduler\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=int(0.1 * total_steps), \n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    epoch_losses = []\n",
    "    metrics_data = []\n",
    "\n",
    "    \n",
    "    # Predefined mapping if needed\n",
    "    label_mapping = {\n",
    "        label.lower(): label for label in label_encoder.classes_\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(\n",
    "                input_ids=input_ids, \n",
    "                attention_mask=attention_mask, \n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Predict intents by generating text\n",
    "            with torch.no_grad():\n",
    "                generated_ids = model.t5.generate(\n",
    "                    input_ids=input_ids, \n",
    "                    attention_mask=attention_mask,\n",
    "                    max_length=128\n",
    "                )\n",
    "                \n",
    "                # Decode generated texts\n",
    "                preds = [tokenizer.decode(g, skip_special_tokens=True).lower().strip() for g in generated_ids]\n",
    "                true_labels = [tokenizer.decode(l, skip_special_tokens=True).lower().strip() for l in labels]\n",
    "                \n",
    "                # Robust label matching\n",
    "                def match_label(pred):\n",
    "                    # Exact match\n",
    "                    if pred in label_mapping:\n",
    "                        return label_mapping[pred]\n",
    "                    \n",
    "                    # Partial match\n",
    "                    for label, mapped_label in label_mapping.items():\n",
    "                        if pred in label or label in pred:\n",
    "                            return mapped_label\n",
    "                    \n",
    "                    # Fallback to the first label if no match\n",
    "                    return label_encoder.classes_[0]\n",
    "\n",
    "                # Convert predictions and true labels\n",
    "                pred_indices = [label_encoder.transform([match_label(p)])[0] for p in preds]\n",
    "                true_indices = labels.cpu().tolist()\n",
    "                \n",
    "                all_preds.extend(pred_indices)\n",
    "                all_labels.extend(true_indices)\n",
    "\n",
    "            # Log batch loss every 10 batches\n",
    "            if batch_idx % 10 == 0:\n",
    "                writer.add_scalar(\"BatchLoss/train\", loss.item(), epoch * len(train_loader) + batch_idx)\n",
    "\n",
    "        # Rest of the function remains the same...\n",
    "        \n",
    "        # Compute epoch metrics\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        epoch_losses.append(avg_loss)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        # Store metrics for CSV logging\n",
    "        metrics_data.append([epoch + 1, avg_loss, accuracy, precision, recall, f1, epoch_time])\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, Accuracy={accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1-score={f1:.4f}, Time={epoch_time:.2f}s\")\n",
    "\n",
    "        # Log metrics to TensorBoard\n",
    "        writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/train\", accuracy, epoch)\n",
    "        writer.add_scalar(\"Precision/train\", precision, epoch)\n",
    "        writer.add_scalar(\"Recall/train\", recall, epoch)\n",
    "        writer.add_scalar(\"F1-score/train\", f1, epoch)\n",
    "        writer.add_scalar(\"Time/Epoch\", epoch_time, epoch)\n",
    "        \n",
    "    # Save model KPIs as CSV\n",
    "    metrics_df = pd.DataFrame(metrics_data, columns=[\"Epoch\", \"Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"Time (s)\"])\n",
    "    metrics_df.to_csv(os.path.join(model_dir, \"training_metrics.csv\"), index=False)\n",
    "\n",
    "    # Save training loss curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs + 1), epoch_losses, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    loss_plot_path = os.path.join(model_dir, \"training_loss.png\")\n",
    "    plt.savefig(loss_plot_path)\n",
    "    writer.add_figure(\"Training Loss\", plt.gcf(), close=True)\n",
    "\n",
    "    # Save model weights\n",
    "    model_path = os.path.join(model_dir, f\"{model_alias}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_model(model, test_loader, tokenizer, label_encoder, model_alias):\n",
    "    \"\"\"Evaluates the T5 model and saves metrics, logs, and confusion matrix.\"\"\"\n",
    "\n",
    "    device = get_device()\n",
    "    \n",
    "        # Additional MPS-specific configurations\n",
    "    if device.type == 'mps':\n",
    "        model = model.to(device, dtype=torch.float32)\n",
    "        torch.set_default_dtype(torch.float32)\n",
    "    else:\n",
    "        model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # Predefined mapping\n",
    "    label_mapping = {\n",
    "        label.lower(): label for label in label_encoder.classes_\n",
    "    }\n",
    "\n",
    "    # Robust label matching function\n",
    "    def match_label(pred):\n",
    "        # Exact match\n",
    "        if pred in label_mapping:\n",
    "            return label_mapping[pred]\n",
    "        \n",
    "        # Partial match\n",
    "        for label, mapped_label in label_mapping.items():\n",
    "            if pred in label or label in pred:\n",
    "                return mapped_label\n",
    "        \n",
    "        # Fallback to the first label if no match\n",
    "        return label_encoder.classes_[0]\n",
    "\n",
    "    # Create directory for storing model metrics\n",
    "    model_dir = f\"model-metric/{model_alias}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize TensorBoard writer\n",
    "    writer = SummaryWriter(log_dir=model_dir)\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            # Generate predictions\n",
    "            generated_ids = model.t5.generate(\n",
    "                input_ids=input_ids, \n",
    "                attention_mask=attention_mask,\n",
    "                max_length=128\n",
    "            )\n",
    "            \n",
    "            # Decode generated texts\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True).lower().strip() for g in generated_ids]\n",
    "            true_labels = [tokenizer.decode(l, skip_special_tokens=True).lower().strip() for l in labels]\n",
    "            \n",
    "            # Convert predicted and true intents to indices\n",
    "            pred_indices = [label_encoder.transform([match_label(p)])[0] for p in preds]\n",
    "            true_indices = [label_encoder.transform([match_label(t)])[0] for t in true_labels]\n",
    "            \n",
    "            all_preds.extend(pred_indices)\n",
    "            all_labels.extend(true_indices)\n",
    "\n",
    "    eval_time = time.time() - start_time\n",
    "    class_names = label_encoder.classes_\n",
    "\n",
    "    # Compute metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "    class_metrics = pd.DataFrame({\n",
    "        'Class': class_names,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Support': support\n",
    "    })\n",
    "\n",
    "    overall_precision, overall_recall, overall_f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    # Print and save classification report\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save confusion matrix plot\n",
    "    confusion_matrix_path = os.path.join(model_dir, \"confusion_matrix.png\")\n",
    "    plt.savefig(confusion_matrix_path)\n",
    "    writer.add_figure(\"Confusion Matrix\", plt.gcf(), close=True)\n",
    "\n",
    "    # Print overall metrics\n",
    "    print(\"\\nPer-class Metrics:\\n\", class_metrics.to_string(index=False))\n",
    "    print(f\"\\nOverall Metrics:\\nPrecision: {overall_precision:.4f}, Recall: {overall_recall:.4f}, F1-score: {overall_f1:.4f}, Eval Time: {eval_time:.2f}s\")\n",
    "\n",
    "    # Log metrics to TensorBoard\n",
    "    writer.add_scalar(\"Precision/test\", overall_precision)\n",
    "    writer.add_scalar(\"Recall/test\", overall_recall)\n",
    "    writer.add_scalar(\"F1-score/test\", overall_f1)\n",
    "    writer.add_scalar(\"Evaluation Time\", eval_time)\n",
    "\n",
    "    # Log per-class metrics\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        writer.add_scalar(f\"Precision/{class_name}\", precision[i])\n",
    "        writer.add_scalar(f\"Recall/{class_name}\", recall[i])\n",
    "        writer.add_scalar(f\"F1-score/{class_name}\", f1[i])\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    # Save evaluation metrics\n",
    "    class_metrics.to_csv(os.path.join(model_dir, \"class_metrics.csv\"), index=False)\n",
    "    cm_df.to_csv(os.path.join(model_dir, \"confusion_matrix.csv\"))\n",
    "\n",
    "    return class_metrics, cm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def export_to_onnx(model, tokenizer, model_alias):\n",
    "    \"\"\"Exports the model to ONNX format.\"\"\"\n",
    "    model.eval().to(\"cpu\")\n",
    "    sample_input = tokenizer(\"test\", return_tensors=\"pt\")\n",
    "    input_names = [\"input_ids\", \"attention_mask\"]\n",
    "    output_names = [\"output\"]\n",
    "    \n",
    "    model_dir = f\"model-metric/{model_alias}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    onnx_path = os.path.join(model_dir, f\"{model_alias}.onnx\")\n",
    "    \n",
    "    torch.onnx.export(\n",
    "        model, \n",
    "        (sample_input[\"input_ids\"], sample_input[\"attention_mask\"]), \n",
    "        onnx_path, \n",
    "        input_names=input_names, \n",
    "        output_names=output_names, \n",
    "        dynamic_axes={\n",
    "            \"input_ids\": {0: \"batch\", 1: \"sequence\"}, \n",
    "            \"attention_mask\": {0: \"batch\", 1: \"sequence\"}, \n",
    "            \"output\": {0: \"batch\"}\n",
    "        }\n",
    "    )\n",
    "    print(f\"ONNX model exported to {onnx_path}\")\n",
    "    return onnx_path\n",
    "\n",
    "def run_onnx_inference(onnx_path, input_ids, attention_mask):\n",
    "    \"\"\"Runs inference using ONNX Runtime.\"\"\"\n",
    "    ort_session = ort.InferenceSession(onnx_path)\n",
    "    ort_inputs = {\"input_ids\": input_ids.tolist(), \"attention_mask\": attention_mask.tolist()}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)\n",
    "    return torch.tensor(np.array(ort_outputs[0]), dtype=torch.float32)\n",
    "\n",
    "def compare_inference_performance(model, tokenizer, test_df, label_encoder, model_alias):\n",
    "    \"\"\"Compares inference performance between PyTorch and ONNX Runtime.\"\"\"\n",
    "    model_dir = f\"model-metric/{model_alias}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=model_dir)\n",
    "    \n",
    "    sample_batch = test_df.sample(50)\n",
    "    test_dataset_batch = CustomDataset(sample_batch, tokenizer)\n",
    "    test_loader_batch = DataLoader(test_dataset_batch, batch_size=len(sample_batch), shuffle=False)\n",
    "    batch = next(iter(test_loader_batch))\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    \n",
    "    # PyTorch Inference\n",
    "    model.eval().to(device)\n",
    "    start_time_torch = time.time()\n",
    "    with torch.no_grad():\n",
    "        torch_outputs = model(input_ids.to(device), attention_mask.to(device)).cpu()\n",
    "    latency_torch = time.time() - start_time_torch\n",
    "    throughput_torch = len(sample_batch) / latency_torch\n",
    "    \n",
    "    # ONNX Inference\n",
    "    onnx_path = export_to_onnx(model, tokenizer, model_alias)\n",
    "    start_time_onnx = time.time()\n",
    "    onnx_outputs = run_onnx_inference(onnx_path, input_ids, attention_mask)\n",
    "    latency_onnx = time.time() - start_time_onnx\n",
    "    throughput_onnx = len(sample_batch) / latency_onnx\n",
    "    \n",
    "    print(f\"PyTorch Inference - Latency: {latency_torch:.4f}s, Throughput: {throughput_torch:.2f} samples/s\")\n",
    "    print(f\"ONNX Inference - Latency: {latency_onnx:.4f}s, Throughput: {throughput_onnx:.2f} samples/s\")\n",
    "    \n",
    "    torch_preds = torch.argmax(torch_outputs, dim=1).tolist()\n",
    "    onnx_preds = torch.argmax(onnx_outputs, dim=1).tolist()\n",
    "    actual_labels = labels.tolist()\n",
    "    \n",
    "    # Compare predictions\n",
    "    torch_report = classification_report(actual_labels, torch_preds, target_names=label_encoder.classes_, output_dict=True)\n",
    "    onnx_report = classification_report(actual_labels, onnx_preds, target_names=label_encoder.classes_, output_dict=True)\n",
    "    \n",
    "    torch_df = pd.DataFrame(torch_report).transpose()\n",
    "    onnx_df = pd.DataFrame(onnx_report).transpose()\n",
    "    \n",
    "    torch_df.to_csv(os.path.join(model_dir, \"torch_classification_report.csv\"))\n",
    "    onnx_df.to_csv(os.path.join(model_dir, \"onnx_classification_report.csv\"))\n",
    "    \n",
    "    # Log metrics to TensorBoard\n",
    "    writer.add_scalar(\"Latency/PyTorch\", latency_torch)\n",
    "    writer.add_scalar(\"Throughput/PyTorch\", throughput_torch)\n",
    "    writer.add_scalar(\"Latency/ONNX\", latency_onnx)\n",
    "    writer.add_scalar(\"Throughput/ONNX\", throughput_onnx)\n",
    "    \n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    \n",
    "    return torch_df, onnx_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(labels, num_classes):\n",
    "    counter = Counter(labels)\n",
    "    total_samples = len(labels)\n",
    "    weights = [total_samples / (num_classes * counter[i]) for i in range(num_classes)]\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Training Script\n",
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "model_alias = 'flan-t5-intent'\n",
    "update_model_dict(model_alias, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS GPU\n",
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"device: {get_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original distribution:\n",
      " issue_area\n",
      "Cancellations and returns    286\n",
      "Order                        270\n",
      "Login and Account            151\n",
      "Shopping                     116\n",
      "Warranty                     105\n",
      "Shipping                      72\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df, label_encoder = load_and_preprocess_data()\n",
    "balanced_df = balance_dataset(df)\n",
    "balanced_df['conversation'] = balanced_df['conversation'].apply(preprocess_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and DataLoaders\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader, test_loader, test_df = create_dataloaders(balanced_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "# Model Initialization and Training\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = FlanT5WithLoRA(num_labels=num_classes)\n",
    "\n",
    "class_weights = compute_class_weights(balanced_df['labels'], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n",
      "/Users/manmehro1/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass-multioutput and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 108\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, tokenizer, model_alias, epochs, learning_rate)\u001b[0m\n\u001b[1;32m    106\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m    107\u001b[0m epoch_losses\u001b[38;5;241m.\u001b[39mappend(avg_loss)\n\u001b[0;32m--> 108\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m precision, recall, f1, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(all_labels, all_preds, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    110\u001b[0m epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:227\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m    226\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 227\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/repository/lora-training-explaination/verizon-poc/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:107\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    104\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    109\u001b[0m             type_true, type_pred\n\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    114\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass-multioutput and multiclass targets"
     ]
    }
   ],
   "source": [
    "train_model(model,train_loader, tokenizer,model_alias=model_alias, epochs=10, learning_rate=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "evaluate_model(\n",
    "    model, \n",
    "    test_loader, \n",
    "    tokenizer, \n",
    "    label_encoder, \n",
    "    model_alias\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model exported to model-metric/distilbert-cased/distilbert-cased.onnx\n",
      "PyTorch Inference - Latency: 4.0829s, Throughput: 12.25 samples/s\n",
      "ONNX Inference - Latency: 6.1786s, Throughput: 8.09 samples/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                           precision    recall  f1-score  support\n",
       " Cancellations and returns   0.714286  0.833333  0.769231     6.00\n",
       " Login and Account           1.000000  1.000000  1.000000     5.00\n",
       " Order                       0.900000  0.818182  0.857143    11.00\n",
       " Shipping                    0.875000  0.875000  0.875000     8.00\n",
       " Shopping                    1.000000  1.000000  1.000000     9.00\n",
       " Warranty                    1.000000  1.000000  1.000000    11.00\n",
       " accuracy                    0.920000  0.920000  0.920000     0.92\n",
       " macro avg                   0.914881  0.921086  0.916896    50.00\n",
       " weighted avg                0.923714  0.920000  0.920879    50.00,\n",
       "                            precision    recall  f1-score  support\n",
       " Cancellations and returns   0.714286  0.833333  0.769231     6.00\n",
       " Login and Account           1.000000  1.000000  1.000000     5.00\n",
       " Order                       0.900000  0.818182  0.857143    11.00\n",
       " Shipping                    0.875000  0.875000  0.875000     8.00\n",
       " Shopping                    1.000000  1.000000  1.000000     9.00\n",
       " Warranty                    1.000000  1.000000  1.000000    11.00\n",
       " accuracy                    0.920000  0.920000  0.920000     0.92\n",
       " macro avg                   0.914881  0.921086  0.916896    50.00\n",
       " weighted avg                0.923714  0.920000  0.920879    50.00)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_inference_performance(model, tokenizer, test_df, label_encoder, model_alias=model_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model-metric/distilbert-cased/tokenizer/tokenizer_config.json',\n",
       " 'model-metric/distilbert-cased/tokenizer/special_tokens_map.json',\n",
       " 'model-metric/distilbert-cased/tokenizer/vocab.txt',\n",
       " 'model-metric/distilbert-cased/tokenizer/added_tokens.json',\n",
       " 'model-metric/distilbert-cased/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(f\"model-metric/{model_alias}/tokenizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['conversation'].str.("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Login and Account', 'Cancellations and returns', 'Order',\n",
       "       'Shopping', 'Warranty', 'Shipping'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['issue_area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
